{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras_vggface\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import mtcnn\n",
    "import scipy.spatial.distance as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "from keras_vggface import utils\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Similarity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First of all, I'm using MTCNN (Multi-task Cascaded Neural Network) in order to predict the location of the face in the image so that we would be able to crop only the face, so that we don't let the background to interfere with our similarity calculation later on. Then, we use VGGFace (with the model resnet50) in order to extract the features of the facial image in the form of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_features = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), # use vggface model that is used by resnet50\n",
    "                                pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(224, 224)):\n",
    "    pixels = plt.imread(filename)\n",
    "    detector = MTCNN()\n",
    "    results = detector.detect_faces(pixels) # detect face inside a box\n",
    "    x1, y1, width, height = results[0]['box'] \n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size) # resize to 224,224 because vgg model requires it to be that way \n",
    "    face_array = np.asarray(image)\n",
    "#     plt.imshow(face_array)\n",
    "#     plt.show() # to show the cropped image\n",
    "    pixels = face_array.astype('float32')\n",
    "    pixels = tf.expand_dims(pixels, axis=0)\n",
    "    samples = utils.preprocess_input(pixels, version=2) \n",
    "    features = resnet50_features.predict(samples)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first use the images of male actors before proceeding with female actresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/Users/valencialie/Desktop/CZ1016_DS2/kdrama/facial similarity/Images/Male\"\n",
    "# change the working directory to the path where the images are located\n",
    "# please change accordingly\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.jpeg'):\n",
    "          # adds only the image files ending with jpeg to the list\n",
    "            actors.append(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will insert all the names of the actors as well as the extracted features into a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for actor in actors:\n",
    "    try:\n",
    "        feat = extract_face(actor)\n",
    "        data[actor] = feat\n",
    "    except:\n",
    "        data[actor] = \"Blank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, we ensure that all the features of the actors are extracted well (meaning there isn't going to be a \"Blank\" inside the dictionary value for every key inside the dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { label: value for label, value in zip(keys, values) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d.items(), columns=['Actor', 'Array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valencialie/opt/anaconda3/envs/keras/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:55: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>Array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Actor, Array]\n",
       "Index: []"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Array == \"Blank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the cosine similarity between all the extracted features. We will take out the top 10 most similar looking actor (as well as their corresponding extracted features) to every actors in this dataframe by using 2 for loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "dist_list2 = []\n",
    "index = []\n",
    "zipped_lists = []\n",
    "sorted_zipped_lists = []\n",
    "top10 = []\n",
    "overall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,576):\n",
    "    for i in range(0,576):\n",
    "        if i == j:\n",
    "            continue\n",
    "        else:\n",
    "            dist = sp.cosine(values[i], values[j])\n",
    "            dist_list.append(dist)\n",
    "            dist_list2.append(dist)\n",
    "            index.append(i)\n",
    "            dist_list.sort()\n",
    "            top10 = dist_list[:10]\n",
    "            zipped_lists = zip(dist_list2, index)\n",
    "            sorted_zipped_lists = sorted(zipped_lists)\n",
    "            sorted_list1 = [element for _, element in sorted_zipped_lists]\n",
    "            top10.extend(sorted_list1[:10])\n",
    "    overall.append(top10)\n",
    "    dist_list = []\n",
    "    dist_list2 = []\n",
    "    index = []\n",
    "    zipped_lists = []\n",
    "    sorted_list1 =[]\n",
    "    top10 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(overall,columns=['Least_Array_Diff', '2ndLeast_Array_Diff','3rdLeast_Array_Diff', '4thLeast_Array_Diff', '5thLeast_Array_Diff', '6thLeast_Array_Diff', '7thLeast_Array_Diff','8thLeast_Array_Diff', '9thLeast_Array_Diff', '10thLeast_Array_Diff','1stMatch', '2ndMatch', '3rdMatch', '4thMatch', '5thMatch', '6thMatch', '7thMatch', '8thMatch', '9thMatch', '10thMatch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, df1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Actor\"] = df2[\"Actor\"].str.replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Actor\"] = df2[\"Actor\"].str.replace(\".jpeg\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    bestmatch.append(df2.iloc[df2['1stMatch'][i], 0])\n",
    "    \n",
    "secondmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    secondmatch.append(df2.iloc[df2['2ndMatch'][i], 0])\n",
    "    \n",
    "thirdmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    thirdmatch.append(df2.iloc[df2['3rdMatch'][i], 0])\n",
    "    \n",
    "fourthmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    fourthmatch.append(df2.iloc[df2['4thMatch'][i], 0])\n",
    "\n",
    "fifthmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    fifthmatch.append(df2.iloc[df2['5thMatch'][i], 0])\n",
    "    \n",
    "sixthmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    sixthmatch.append(df2.iloc[df2['6thMatch'][i], 0])\n",
    "    \n",
    "seventhmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    seventhmatch.append(df2.iloc[df2['7thMatch'][i], 0])\n",
    "    \n",
    "eighthmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    eighthmatch.append(df2.iloc[df2['8thMatch'][i], 0])\n",
    "    \n",
    "ninthmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    ninthmatch.append(df2.iloc[df2['9thMatch'][i], 0])\n",
    "    \n",
    "tenthmatch = []\n",
    "\n",
    "for i in range(0,576):\n",
    "    tenthmatch.append(df2.iloc[df2['10thMatch'][i], 0])\n",
    "\n",
    "df3 = pd.DataFrame(bestmatch,columns=['Best_Match_Actor'])\n",
    "df4 = pd.DataFrame(secondmatch,columns=['Second_Match_Actor'])\n",
    "df5 = pd.DataFrame(thirdmatch,columns=['Third_Match_Actor'])\n",
    "df6 = pd.DataFrame(fourthmatch,columns=['Fourth_Match_Actor'])\n",
    "df7 = pd.DataFrame(fifthmatch,columns=['Fifth_Match_Actor'])\n",
    "df8 = pd.DataFrame(sixthmatch,columns=['Sixth_Match_Actor'])\n",
    "df9 = pd.DataFrame(seventhmatch,columns=['Seventh_Match_Actor'])\n",
    "df10 = pd.DataFrame(eighthmatch,columns=['Eighth_Match_Actor'])\n",
    "df11 = pd.DataFrame(ninthmatch,columns=['Ninth_Match_Actor'])\n",
    "df12 = pd.DataFrame(tenthmatch,columns=['Tenth_Match_Actor'])\n",
    "\n",
    "df13 = pd.concat([df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>Array</th>\n",
       "      <th>Least_Array_Diff</th>\n",
       "      <th>2ndLeast_Array_Diff</th>\n",
       "      <th>3rdLeast_Array_Diff</th>\n",
       "      <th>4thLeast_Array_Diff</th>\n",
       "      <th>5thLeast_Array_Diff</th>\n",
       "      <th>6thLeast_Array_Diff</th>\n",
       "      <th>7thLeast_Array_Diff</th>\n",
       "      <th>8thLeast_Array_Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>Best_Match_Actor</th>\n",
       "      <th>Second_Match_Actor</th>\n",
       "      <th>Third_Match_Actor</th>\n",
       "      <th>Fourth_Match_Actor</th>\n",
       "      <th>Fifth_Match_Actor</th>\n",
       "      <th>Sixth_Match_Actor</th>\n",
       "      <th>Seventh_Match_Actor</th>\n",
       "      <th>Eighth_Match_Actor</th>\n",
       "      <th>Ninth_Match_Actor</th>\n",
       "      <th>Tenth_Match_Actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeeKyuHan</td>\n",
       "      <td>[[0.0, 0.06436636, 0.0, 0.0, 2.1942368, 0.1459...</td>\n",
       "      <td>0.296106</td>\n",
       "      <td>0.317963</td>\n",
       "      <td>0.331765</td>\n",
       "      <td>0.346518</td>\n",
       "      <td>0.346633</td>\n",
       "      <td>0.353566</td>\n",
       "      <td>0.358768</td>\n",
       "      <td>0.361260</td>\n",
       "      <td>...</td>\n",
       "      <td>YangKyungWon</td>\n",
       "      <td>YoonKyunSang</td>\n",
       "      <td>LeeDongHae</td>\n",
       "      <td>OhDaeHwan</td>\n",
       "      <td>LeeYiKyung</td>\n",
       "      <td>OhJungSe</td>\n",
       "      <td>GongYoo</td>\n",
       "      <td>ParkEunSeok</td>\n",
       "      <td>HyunBin</td>\n",
       "      <td>JaeHee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ImShiWan</td>\n",
       "      <td>[[0.0, 0.0, 1.957572, 0.0, 1.343608, 2.250862,...</td>\n",
       "      <td>0.345610</td>\n",
       "      <td>0.361965</td>\n",
       "      <td>0.364178</td>\n",
       "      <td>0.371152</td>\n",
       "      <td>0.376647</td>\n",
       "      <td>0.382276</td>\n",
       "      <td>0.383490</td>\n",
       "      <td>0.385891</td>\n",
       "      <td>...</td>\n",
       "      <td>LeeTaeRi</td>\n",
       "      <td>LeeJongWon</td>\n",
       "      <td>LeeSeoWon</td>\n",
       "      <td>YoonSunWoo</td>\n",
       "      <td>JiIlJoo</td>\n",
       "      <td>SongJoongKi</td>\n",
       "      <td>JungJinWoon</td>\n",
       "      <td>ParkHaeJin</td>\n",
       "      <td>HanGiChan</td>\n",
       "      <td>KimJungHyun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaeHee</td>\n",
       "      <td>[[0.0, 1.1606871, 0.0, 0.8187124, 0.12278407, ...</td>\n",
       "      <td>0.294929</td>\n",
       "      <td>0.308964</td>\n",
       "      <td>0.319130</td>\n",
       "      <td>0.348895</td>\n",
       "      <td>0.359478</td>\n",
       "      <td>0.359915</td>\n",
       "      <td>0.361896</td>\n",
       "      <td>0.362959</td>\n",
       "      <td>...</td>\n",
       "      <td>SeoJiHoon</td>\n",
       "      <td>ParkEunSeok</td>\n",
       "      <td>YangKyungWon</td>\n",
       "      <td>JiChangWook</td>\n",
       "      <td>LeeTaeRi</td>\n",
       "      <td>KimWooBin</td>\n",
       "      <td>JooSangWook</td>\n",
       "      <td>JungGunJoo</td>\n",
       "      <td>LeeYiKyung</td>\n",
       "      <td>LeeKyuHan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KimSungOh</td>\n",
       "      <td>[[0.0744203, 0.27144027, 3.1494617, 0.13220347...</td>\n",
       "      <td>0.349409</td>\n",
       "      <td>0.376483</td>\n",
       "      <td>0.399360</td>\n",
       "      <td>0.411211</td>\n",
       "      <td>0.412942</td>\n",
       "      <td>0.426894</td>\n",
       "      <td>0.435751</td>\n",
       "      <td>0.441681</td>\n",
       "      <td>...</td>\n",
       "      <td>ParkEunSeok</td>\n",
       "      <td>YangKyungWon</td>\n",
       "      <td>LeeJaeYoon</td>\n",
       "      <td>OhnJooWan</td>\n",
       "      <td>ChoiDaniel</td>\n",
       "      <td>JungGunJoo</td>\n",
       "      <td>KimJiHoon</td>\n",
       "      <td>LeeDongHae</td>\n",
       "      <td>ShinSeungHwan</td>\n",
       "      <td>WooJungKook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JoHeeBong</td>\n",
       "      <td>[[2.405822, 0.25564858, 0.0, 0.62448454, 0.878...</td>\n",
       "      <td>0.361091</td>\n",
       "      <td>0.392543</td>\n",
       "      <td>0.396306</td>\n",
       "      <td>0.419863</td>\n",
       "      <td>0.427464</td>\n",
       "      <td>0.432157</td>\n",
       "      <td>0.437181</td>\n",
       "      <td>0.438818</td>\n",
       "      <td>...</td>\n",
       "      <td>LeeSungJae</td>\n",
       "      <td>ChunHoJin</td>\n",
       "      <td>KimMinSang</td>\n",
       "      <td>KimWonHae</td>\n",
       "      <td>ChunJungMyung</td>\n",
       "      <td>ParkHyukKwon</td>\n",
       "      <td>LeeSungMin</td>\n",
       "      <td>LeeByungHun</td>\n",
       "      <td>LeeDaeYeon</td>\n",
       "      <td>ParkGeonRak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actor                                              Array  \\\n",
       "0  LeeKyuHan  [[0.0, 0.06436636, 0.0, 0.0, 2.1942368, 0.1459...   \n",
       "1   ImShiWan  [[0.0, 0.0, 1.957572, 0.0, 1.343608, 2.250862,...   \n",
       "2     JaeHee  [[0.0, 1.1606871, 0.0, 0.8187124, 0.12278407, ...   \n",
       "3  KimSungOh  [[0.0744203, 0.27144027, 3.1494617, 0.13220347...   \n",
       "4  JoHeeBong  [[2.405822, 0.25564858, 0.0, 0.62448454, 0.878...   \n",
       "\n",
       "   Least_Array_Diff  2ndLeast_Array_Diff  3rdLeast_Array_Diff  \\\n",
       "0          0.296106             0.317963             0.331765   \n",
       "1          0.345610             0.361965             0.364178   \n",
       "2          0.294929             0.308964             0.319130   \n",
       "3          0.349409             0.376483             0.399360   \n",
       "4          0.361091             0.392543             0.396306   \n",
       "\n",
       "   4thLeast_Array_Diff  5thLeast_Array_Diff  6thLeast_Array_Diff  \\\n",
       "0             0.346518             0.346633             0.353566   \n",
       "1             0.371152             0.376647             0.382276   \n",
       "2             0.348895             0.359478             0.359915   \n",
       "3             0.411211             0.412942             0.426894   \n",
       "4             0.419863             0.427464             0.432157   \n",
       "\n",
       "   7thLeast_Array_Diff  8thLeast_Array_Diff  ...  Best_Match_Actor  \\\n",
       "0             0.358768             0.361260  ...      YangKyungWon   \n",
       "1             0.383490             0.385891  ...          LeeTaeRi   \n",
       "2             0.361896             0.362959  ...         SeoJiHoon   \n",
       "3             0.435751             0.441681  ...       ParkEunSeok   \n",
       "4             0.437181             0.438818  ...        LeeSungJae   \n",
       "\n",
       "   Second_Match_Actor  Third_Match_Actor  Fourth_Match_Actor  \\\n",
       "0        YoonKyunSang         LeeDongHae           OhDaeHwan   \n",
       "1          LeeJongWon          LeeSeoWon          YoonSunWoo   \n",
       "2         ParkEunSeok       YangKyungWon         JiChangWook   \n",
       "3        YangKyungWon         LeeJaeYoon           OhnJooWan   \n",
       "4           ChunHoJin         KimMinSang           KimWonHae   \n",
       "\n",
       "   Fifth_Match_Actor  Sixth_Match_Actor  Seventh_Match_Actor  \\\n",
       "0         LeeYiKyung           OhJungSe              GongYoo   \n",
       "1            JiIlJoo        SongJoongKi          JungJinWoon   \n",
       "2           LeeTaeRi          KimWooBin          JooSangWook   \n",
       "3         ChoiDaniel         JungGunJoo            KimJiHoon   \n",
       "4      ChunJungMyung       ParkHyukKwon           LeeSungMin   \n",
       "\n",
       "   Eighth_Match_Actor  Ninth_Match_Actor  Tenth_Match_Actor  \n",
       "0         ParkEunSeok            HyunBin             JaeHee  \n",
       "1          ParkHaeJin          HanGiChan        KimJungHyun  \n",
       "2          JungGunJoo         LeeYiKyung          LeeKyuHan  \n",
       "3          LeeDongHae      ShinSeungHwan        WooJungKook  \n",
       "4         LeeByungHun         LeeDaeYeon        ParkGeonRak  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df13.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will do the same exact steps to all the female actresses as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "actresses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r\"/Users/valencialie/Desktop/CZ1016_DS2/kdrama/facial similarity/Images/Female\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.jpeg'):\n",
    "          # adds only the image files ending with jpeg to the list\n",
    "            actresses.append(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataF = {}\n",
    "\n",
    "for actress in actresses:\n",
    "    try:\n",
    "        feat = extract_face(actress)\n",
    "        dataF[actress] = feat\n",
    "    except:\n",
    "        dataF[actress] = \"Blank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(dataF.keys())\n",
    "values = list(dataF.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = { label: value for label, value in zip(label, values) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dF = pd.DataFrame(f.items(), columns=['Actor', 'Array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valencialie/opt/anaconda3/envs/keras/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:55: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>Array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Actor, Array]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF[dF.Array == \"Blank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "dist_list2 = []\n",
    "index = []\n",
    "zipped_lists = []\n",
    "sorted_zipped_lists = []\n",
    "top10 = []\n",
    "overall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,474):\n",
    "    for i in range(0,474):\n",
    "        if i == j:\n",
    "            continue\n",
    "        else:\n",
    "            dist = sp.cosine(values[i], values[j])\n",
    "            dist_list.append(dist)\n",
    "            dist_list2.append(dist)\n",
    "            index.append(i)\n",
    "            dist_list.sort()\n",
    "            top10 = dist_list[:10]\n",
    "            zipped_lists = zip(dist_list2, index)\n",
    "            sorted_zipped_lists = sorted(zipped_lists)\n",
    "            sorted_list1 = [element for _, element in sorted_zipped_lists]\n",
    "            top10.extend(sorted_list1[:10])\n",
    "    overall.append(top10)\n",
    "    dist_list = []\n",
    "    dist_list2 = []\n",
    "    index = []\n",
    "    zipped_lists = []\n",
    "    sorted_list1 =[]\n",
    "    top10 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dF1 = pd.DataFrame(overall,columns=['Least_Array_Diff', '2ndLeast_Array_Diff','3rdLeast_Array_Diff', '4thLeast_Array_Diff', '5thLeast_Array_Diff', '6thLeast_Array_Diff', '7thLeast_Array_Diff','8thLeast_Array_Diff', '9thLeast_Array_Diff', '10thLeast_Array_Diff','1stMatch', '2ndMatch', '3rdMatch', '4thMatch', '5thMatch', '6thMatch', '7thMatch', '8thMatch', '9thMatch', '10thMatch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dF2 = pd.concat([dF, dF1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dF2[\"Actor\"] = dF2[\"Actor\"].str.replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dF2[\"Actor\"] = dF2[\"Actor\"].str.replace(\".jpeg\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    bestmatch.append(dF2.iloc[dF2['1stMatch'][i], 0])\n",
    "    \n",
    "secondmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    secondmatch.append(dF2.iloc[dF2['2ndMatch'][i], 0])\n",
    "    \n",
    "thirdmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    thirdmatch.append(dF2.iloc[dF2['3rdMatch'][i], 0])\n",
    "    \n",
    "fourthmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    fourthmatch.append(dF2.iloc[dF2['4thMatch'][i], 0])\n",
    "\n",
    "fifthmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    fifthmatch.append(dF2.iloc[dF2['5thMatch'][i], 0])\n",
    "    \n",
    "sixthmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    sixthmatch.append(dF2.iloc[dF2['6thMatch'][i], 0])\n",
    "    \n",
    "seventhmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    seventhmatch.append(dF2.iloc[dF2['7thMatch'][i], 0])\n",
    "    \n",
    "eighthmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    eighthmatch.append(dF2.iloc[dF2['8thMatch'][i], 0])\n",
    "    \n",
    "ninthmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    ninthmatch.append(dF2.iloc[dF2['9thMatch'][i], 0])\n",
    "    \n",
    "tenthmatch = []\n",
    "\n",
    "for i in range(0,474):\n",
    "    tenthmatch.append(dF2.iloc[dF2['10thMatch'][i], 0])\n",
    "\n",
    "dF3 = pd.DataFrame(bestmatch,columns=['Best_Match_Actor'])\n",
    "dF4 = pd.DataFrame(secondmatch,columns=['Second_Match_Actor'])\n",
    "dF5 = pd.DataFrame(thirdmatch,columns=['Third_Match_Actor'])\n",
    "dF6 = pd.DataFrame(fourthmatch,columns=['Fourth_Match_Actor'])\n",
    "dF7 = pd.DataFrame(fifthmatch,columns=['Fifth_Match_Actor'])\n",
    "dF8 = pd.DataFrame(sixthmatch,columns=['Sixth_Match_Actor'])\n",
    "dF9 = pd.DataFrame(seventhmatch,columns=['Seventh_Match_Actor'])\n",
    "dF10 = pd.DataFrame(eighthmatch,columns=['Eighth_Match_Actor'])\n",
    "dF11 = pd.DataFrame(ninthmatch,columns=['Ninth_Match_Actor'])\n",
    "dF12 = pd.DataFrame(tenthmatch,columns=['Tenth_Match_Actor'])\n",
    "\n",
    "dF13 = pd.concat([dF2, dF3, dF4, dF5, dF6, dF7, dF8, dF9, dF10, dF11, dF12], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>Array</th>\n",
       "      <th>Least_Array_Diff</th>\n",
       "      <th>2ndLeast_Array_Diff</th>\n",
       "      <th>3rdLeast_Array_Diff</th>\n",
       "      <th>4thLeast_Array_Diff</th>\n",
       "      <th>5thLeast_Array_Diff</th>\n",
       "      <th>6thLeast_Array_Diff</th>\n",
       "      <th>7thLeast_Array_Diff</th>\n",
       "      <th>8thLeast_Array_Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>Best_Match_Actor</th>\n",
       "      <th>Second_Match_Actor</th>\n",
       "      <th>Third_Match_Actor</th>\n",
       "      <th>Fourth_Match_Actor</th>\n",
       "      <th>Fifth_Match_Actor</th>\n",
       "      <th>Sixth_Match_Actor</th>\n",
       "      <th>Seventh_Match_Actor</th>\n",
       "      <th>Eighth_Match_Actor</th>\n",
       "      <th>Ninth_Match_Actor</th>\n",
       "      <th>Tenth_Match_Actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JungYooJin</td>\n",
       "      <td>[[0.0, 0.2543437, 0.0, 4.4913435, 3.635107, 0....</td>\n",
       "      <td>0.275907</td>\n",
       "      <td>0.301436</td>\n",
       "      <td>0.301582</td>\n",
       "      <td>0.313293</td>\n",
       "      <td>0.317468</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.321265</td>\n",
       "      <td>0.321366</td>\n",
       "      <td>...</td>\n",
       "      <td>KwonNaRa</td>\n",
       "      <td>SongHyeKyo</td>\n",
       "      <td>YooDaIn</td>\n",
       "      <td>SonYeJin</td>\n",
       "      <td>ShinSeKyung</td>\n",
       "      <td>LeeHaNa</td>\n",
       "      <td>KimJiWon</td>\n",
       "      <td>KimYoonHye</td>\n",
       "      <td>HanBoReum</td>\n",
       "      <td>ChoYeoJung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SeoYiAhn</td>\n",
       "      <td>[[1.1509761, 0.047182605, 2.0433936, 0.5478225...</td>\n",
       "      <td>0.305233</td>\n",
       "      <td>0.340385</td>\n",
       "      <td>0.346528</td>\n",
       "      <td>0.360276</td>\n",
       "      <td>0.377073</td>\n",
       "      <td>0.377606</td>\n",
       "      <td>0.380573</td>\n",
       "      <td>0.385373</td>\n",
       "      <td>...</td>\n",
       "      <td>SonHwaRyung</td>\n",
       "      <td>KimHyunJoo</td>\n",
       "      <td>LeeBoYoung</td>\n",
       "      <td>LeeHwiHyang</td>\n",
       "      <td>GoYoonJung</td>\n",
       "      <td>GilEunHye</td>\n",
       "      <td>KimTaeHee</td>\n",
       "      <td>SeoJiHye</td>\n",
       "      <td>JungRyeoWon</td>\n",
       "      <td>HanSunHwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KangYeNa</td>\n",
       "      <td>[[1.9589509, 0.0, 0.40266016, 0.42564636, 2.02...</td>\n",
       "      <td>0.371118</td>\n",
       "      <td>0.399121</td>\n",
       "      <td>0.402775</td>\n",
       "      <td>0.414845</td>\n",
       "      <td>0.419751</td>\n",
       "      <td>0.429579</td>\n",
       "      <td>0.432363</td>\n",
       "      <td>0.434435</td>\n",
       "      <td>...</td>\n",
       "      <td>GoAhRa</td>\n",
       "      <td>Uee</td>\n",
       "      <td>SaHyunJin</td>\n",
       "      <td>LeeShiYoung</td>\n",
       "      <td>ImSungEon</td>\n",
       "      <td>HanHyoJoo</td>\n",
       "      <td>OhNaRa</td>\n",
       "      <td>LeeHeeWon</td>\n",
       "      <td>JangYoungNam</td>\n",
       "      <td>SeoWoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KimHyunSoo</td>\n",
       "      <td>[[0.0, 0.14416984, 4.598352, 0.061391816, 5.13...</td>\n",
       "      <td>0.305612</td>\n",
       "      <td>0.317215</td>\n",
       "      <td>0.319267</td>\n",
       "      <td>0.340414</td>\n",
       "      <td>0.343880</td>\n",
       "      <td>0.348375</td>\n",
       "      <td>0.352641</td>\n",
       "      <td>0.355292</td>\n",
       "      <td>...</td>\n",
       "      <td>KimSoHyun</td>\n",
       "      <td>JungDaBin</td>\n",
       "      <td>RyuHwaYoung</td>\n",
       "      <td>YoonEunHye</td>\n",
       "      <td>NaEunSaem</td>\n",
       "      <td>GoAhSung</td>\n",
       "      <td>SonDamBi</td>\n",
       "      <td>HanJiEun</td>\n",
       "      <td>ParkJooMi</td>\n",
       "      <td>HanGroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YooHyeRi</td>\n",
       "      <td>[[0.47068676, 0.82373685, 1.8157511, 2.4260333...</td>\n",
       "      <td>0.401623</td>\n",
       "      <td>0.409698</td>\n",
       "      <td>0.411395</td>\n",
       "      <td>0.416729</td>\n",
       "      <td>0.426655</td>\n",
       "      <td>0.426857</td>\n",
       "      <td>0.432220</td>\n",
       "      <td>0.441863</td>\n",
       "      <td>...</td>\n",
       "      <td>ShimHyeJin</td>\n",
       "      <td>KimSunAh</td>\n",
       "      <td>YooSeoJin</td>\n",
       "      <td>KimMinSeo</td>\n",
       "      <td>ChoiSooRin</td>\n",
       "      <td>KimJeeSoo</td>\n",
       "      <td>ChaeJungAn</td>\n",
       "      <td>JinYeJu</td>\n",
       "      <td>HanBoReum</td>\n",
       "      <td>KimNamJoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Actor                                              Array  \\\n",
       "0  JungYooJin  [[0.0, 0.2543437, 0.0, 4.4913435, 3.635107, 0....   \n",
       "1    SeoYiAhn  [[1.1509761, 0.047182605, 2.0433936, 0.5478225...   \n",
       "2    KangYeNa  [[1.9589509, 0.0, 0.40266016, 0.42564636, 2.02...   \n",
       "3  KimHyunSoo  [[0.0, 0.14416984, 4.598352, 0.061391816, 5.13...   \n",
       "4    YooHyeRi  [[0.47068676, 0.82373685, 1.8157511, 2.4260333...   \n",
       "\n",
       "   Least_Array_Diff  2ndLeast_Array_Diff  3rdLeast_Array_Diff  \\\n",
       "0          0.275907             0.301436             0.301582   \n",
       "1          0.305233             0.340385             0.346528   \n",
       "2          0.371118             0.399121             0.402775   \n",
       "3          0.305612             0.317215             0.319267   \n",
       "4          0.401623             0.409698             0.411395   \n",
       "\n",
       "   4thLeast_Array_Diff  5thLeast_Array_Diff  6thLeast_Array_Diff  \\\n",
       "0             0.313293             0.317468             0.321232   \n",
       "1             0.360276             0.377073             0.377606   \n",
       "2             0.414845             0.419751             0.429579   \n",
       "3             0.340414             0.343880             0.348375   \n",
       "4             0.416729             0.426655             0.426857   \n",
       "\n",
       "   7thLeast_Array_Diff  8thLeast_Array_Diff  ...  Best_Match_Actor  \\\n",
       "0             0.321265             0.321366  ...          KwonNaRa   \n",
       "1             0.380573             0.385373  ...       SonHwaRyung   \n",
       "2             0.432363             0.434435  ...            GoAhRa   \n",
       "3             0.352641             0.355292  ...         KimSoHyun   \n",
       "4             0.432220             0.441863  ...        ShimHyeJin   \n",
       "\n",
       "   Second_Match_Actor  Third_Match_Actor  Fourth_Match_Actor  \\\n",
       "0          SongHyeKyo            YooDaIn            SonYeJin   \n",
       "1          KimHyunJoo         LeeBoYoung         LeeHwiHyang   \n",
       "2                 Uee          SaHyunJin         LeeShiYoung   \n",
       "3           JungDaBin        RyuHwaYoung          YoonEunHye   \n",
       "4            KimSunAh          YooSeoJin           KimMinSeo   \n",
       "\n",
       "   Fifth_Match_Actor  Sixth_Match_Actor  Seventh_Match_Actor  \\\n",
       "0        ShinSeKyung            LeeHaNa             KimJiWon   \n",
       "1         GoYoonJung          GilEunHye            KimTaeHee   \n",
       "2          ImSungEon          HanHyoJoo               OhNaRa   \n",
       "3          NaEunSaem           GoAhSung             SonDamBi   \n",
       "4         ChoiSooRin          KimJeeSoo           ChaeJungAn   \n",
       "\n",
       "   Eighth_Match_Actor  Ninth_Match_Actor  Tenth_Match_Actor  \n",
       "0          KimYoonHye          HanBoReum         ChoYeoJung  \n",
       "1            SeoJiHye        JungRyeoWon          HanSunHwa  \n",
       "2           LeeHeeWon       JangYoungNam             SeoWoo  \n",
       "3            HanJiEun          ParkJooMi            HanGroo  \n",
       "4             JinYeJu          HanBoReum          KimNamJoo  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF13.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, we're going to test our model with 10 pictures of the same actor as well as 10 pictures of the same actress. If the cosine distance calculated between these 10 pictures are relatively low, we can assume that this model is doing well because it is able to identiy a person resembling another person well (In this case, it'll be the same person, just different photos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "baesuzy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "baesuzy.append(extract_face(\"baesuzy1.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy2.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy3.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy4.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy5.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy6.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy7.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy8.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy9.jpg\"))\n",
    "\n",
    "baesuzy.append(extract_face(\"baesuzy10.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosinebae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in baesuzy:\n",
    "    cosinebae.append(sp.cosine(i, i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04922724366188049"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average(cosinebae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the average is very low compared to when we are comparing between 2 different people's photo (10 times smaller in terms of distance!), we can say that the model worked well. Now we will try again for another male actor's photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "seoinguk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "seoinguk.append(extract_face(\"seoinguk1.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk2.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk3.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk4.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk5.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk6.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk7.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk8.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk9.jpg\"))\n",
    "\n",
    "seoinguk.append(extract_face(\"seoinguk10.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosineseo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in seoinguk:\n",
    "    cosineseo.append(sp.cosine(i, i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043684196472167966"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average(cosineseo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to our previous findings, the average distance between the 10 photos of the same actor is very very low, compared to when we are comparing between different people. Hence, we will move forward with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to subset the most similar looking actor and actress for every actor and actress in our datasets respectively so that we can recommend a match for them accordingly using the sentiment analysis matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = df13.iloc[:, [0,2,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>Least_Array_Diff</th>\n",
       "      <th>Best_Match_Actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LeeKyuHan</td>\n",
       "      <td>0.296106</td>\n",
       "      <td>YangKyungWon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ImShiWan</td>\n",
       "      <td>0.345610</td>\n",
       "      <td>LeeTaeRi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaeHee</td>\n",
       "      <td>0.294929</td>\n",
       "      <td>SeoJiHoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KimSungOh</td>\n",
       "      <td>0.349409</td>\n",
       "      <td>ParkEunSeok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JoHeeBong</td>\n",
       "      <td>0.361091</td>\n",
       "      <td>LeeSungJae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>DongHa</td>\n",
       "      <td>0.308361</td>\n",
       "      <td>KimHyunJoong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>SungJiRu</td>\n",
       "      <td>0.342572</td>\n",
       "      <td>ChoiMooSung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>KimHyungMin</td>\n",
       "      <td>0.356046</td>\n",
       "      <td>ParkHoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>ParkByungEun</td>\n",
       "      <td>0.346609</td>\n",
       "      <td>KimJoonHan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>LeeHyunJae</td>\n",
       "      <td>0.419547</td>\n",
       "      <td>ParkEunSeok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Actor  Least_Array_Diff Best_Match_Actor\n",
       "0       LeeKyuHan          0.296106     YangKyungWon\n",
       "1        ImShiWan          0.345610         LeeTaeRi\n",
       "2          JaeHee          0.294929        SeoJiHoon\n",
       "3       KimSungOh          0.349409      ParkEunSeok\n",
       "4       JoHeeBong          0.361091       LeeSungJae\n",
       "..            ...               ...              ...\n",
       "571        DongHa          0.308361     KimHyunJoong\n",
       "572      SungJiRu          0.342572      ChoiMooSung\n",
       "573   KimHyungMin          0.356046         ParkHoon\n",
       "574  ParkByungEun          0.346609       KimJoonHan\n",
       "575    LeeHyunJae          0.419547      ParkEunSeok\n",
       "\n",
       "[576 rows x 3 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actor.tocsv('actor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "actress = dF13.iloc[:, [0,2,22]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actress.to_csv('actress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = pd.read_csv(\"senti.csv\")  #dataset from sentiment analysis matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create 2 new columns for us to insert later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti['actor1match'] = np.nan\n",
    "senti['actor2match'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use for loop to loop through every actors in actor in the dataframe and looping it through every actors in the senti csv (actor 1). Once we get a match, we append it inside a list, before inserting it into the senti csv column: actor1match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "match1 = []\n",
    "\n",
    "for j in range (0,102):\n",
    "    for i in range (0,474):\n",
    "        if dF13.Best_Match_Actor[i] == senti.actor1[j]:\n",
    "            match1.append(dF13.Actor[i])\n",
    "            match1.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti[\"actor1match\"]=senti[\"actor1match\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,160):\n",
    "    if str(match1[i]).isdigit() == True and senti.iloc[match1[i], 6] == \"nan\":\n",
    "        senti.at[match1[i], 'actor1match'] = match1[i-1]\n",
    "    elif str(match1[i]).isdigit() == True and senti.iloc[match1[i], 6] != \"nan\":\n",
    "        match.append(senti.iloc[match1[i], 6])\n",
    "        match.append(match1[i-1])\n",
    "        senti.at[match1[i], 'actor1match'] = match\n",
    "        match = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for all actor2 inside the senti csv. We use for loop to loop through every actors in actor in the dataframe and looping it through every actors in the senti csv (actor2). Once we get a match, we append it inside a list, before inserting it into the senti csv column: actor2match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "match2 = []\n",
    "\n",
    "for j in range (0,102):\n",
    "    for i in range (0,474):\n",
    "        if dF13.Best_Match_Actor[i] == senti.actor2[j]:\n",
    "            match2.append(dF13.Actor[i])\n",
    "            match2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti[\"actor2match\"]=senti[\"actor2match\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,126):\n",
    "    if str(match2[i]).isdigit() == True and senti.iloc[match2[i], 7] == \"nan\":\n",
    "        senti.at[match2[i], 'actor2match'] = match2[i-1]\n",
    "    elif str(match2[i]).isdigit() == True and senti.iloc[match2[i], 7] != \"nan\":\n",
    "        match.append(senti.iloc[match2[i], 7])\n",
    "        match.append(match2[i-1])\n",
    "        senti.at[match2[i], 'actor2match'] = match\n",
    "        match = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pair</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>lineCount</th>\n",
       "      <th>score</th>\n",
       "      <th>actor1match</th>\n",
       "      <th>actor2match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>('ChaSeungWon', 'LeeSeungGi')</td>\n",
       "      <td>ChaSeungWon</td>\n",
       "      <td>LeeSeungGi</td>\n",
       "      <td>5</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>('JungHaeIn', 'SonYeJin')</td>\n",
       "      <td>JungHaeIn</td>\n",
       "      <td>SonYeJin</td>\n",
       "      <td>9</td>\n",
       "      <td>0.501087</td>\n",
       "      <td>nan</td>\n",
       "      <td>[[[BangMinAh, KimYooJung], BangMinAh], KimYooJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>('GoSungHee', 'YoonHyunMin')</td>\n",
       "      <td>GoSungHee</td>\n",
       "      <td>YoonHyunMin</td>\n",
       "      <td>5</td>\n",
       "      <td>0.487549</td>\n",
       "      <td>SeoYeJi</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>('ChoiJinHyuk', 'SongJiHyo')</td>\n",
       "      <td>ChoiJinHyuk</td>\n",
       "      <td>SongJiHyo</td>\n",
       "      <td>5</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>nan</td>\n",
       "      <td>[ShinDongMi, ShinDongMi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>('JungEunJi', 'KimJiSoo')</td>\n",
       "      <td>JungEunJi</td>\n",
       "      <td>KimJiSoo</td>\n",
       "      <td>6</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           pair       actor1       actor2  \\\n",
       "0           0  ('ChaSeungWon', 'LeeSeungGi')  ChaSeungWon   LeeSeungGi   \n",
       "1           1      ('JungHaeIn', 'SonYeJin')    JungHaeIn     SonYeJin   \n",
       "2           2   ('GoSungHee', 'YoonHyunMin')    GoSungHee  YoonHyunMin   \n",
       "3           3   ('ChoiJinHyuk', 'SongJiHyo')  ChoiJinHyuk    SongJiHyo   \n",
       "4           4      ('JungEunJi', 'KimJiSoo')    JungEunJi     KimJiSoo   \n",
       "\n",
       "   lineCount     score actor1match  \\\n",
       "0          5  0.592857         nan   \n",
       "1          9  0.501087         nan   \n",
       "2          5  0.487549     SeoYeJi   \n",
       "3          5  0.478333         nan   \n",
       "4          6  0.466667         nan   \n",
       "\n",
       "                                         actor2match  \n",
       "0                                                nan  \n",
       "1  [[[BangMinAh, KimYooJung], BangMinAh], KimYooJ...  \n",
       "2                                                nan  \n",
       "3                           [ShinDongMi, ShinDongMi]  \n",
       "4                                                nan  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only do it for female actresses, now we'll do the same process for male actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "match2 = []\n",
    "\n",
    "for j in range (0,102):\n",
    "    for i in range (0,576):\n",
    "        if df13.Best_Match_Actor[i] == senti.actor2[j]:\n",
    "            match2.append(df13.Actor[i])\n",
    "            match2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,150):\n",
    "    if str(match2[i]).isdigit() == True and senti.iloc[match2[i], 7] == \"nan\":\n",
    "        senti.at[match2[i], 'actor2match'] = match2[i-1]\n",
    "    elif str(match2[i]).isdigit() == True and senti.iloc[match2[i], 7] != \"nan\":\n",
    "        match.append(senti.iloc[match2[i], 7])\n",
    "        match.append(match2[i-1])\n",
    "        senti.at[match2[i], 'actor2match'] = match\n",
    "        match = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "match1 = []\n",
    "\n",
    "for j in range (0,102):\n",
    "    for i in range (0,576):\n",
    "        if df13.Best_Match_Actor[i] == senti.actor1[j]:\n",
    "            match1.append(df13.Actor[i])\n",
    "            match1.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,74):\n",
    "    if str(match1[i]).isdigit() == True and senti.iloc[match1[i], 6] == \"nan\":\n",
    "        senti.at[match1[i], 'actor1match'] = match1[i-1]\n",
    "    elif str(match1[i]).isdigit() == True and senti.iloc[match1[i], 6] != \"nan\":\n",
    "        match.append(senti.iloc[match1[i], 6])\n",
    "        match.append(match1[i-1])\n",
    "        senti.at[match1[i], 'actor1match'] = match\n",
    "        match = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the csv because there are lots of unnecessary '[' and ']' but before that we export it into a csv and then clean it because that way, all the square brackets will just be considered string instead of list so itll be easier to clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senti.to_csv(\"sentiunclean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiunclean = pd.read_csv(\"sentiunclean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor1match = [i.replace('[','').replace(']','').replace(\"'\",'') if type(i)==str else '' for i in sentiunclean['actor1match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor2match = [i.replace('[','').replace(']','').replace(\"'\",'') if type(i)==str else '' for i in sentiunclean['actor2match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiunclean = sentiunclean.drop(columns = ['actor1match', 'actor2match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>pair</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor2</th>\n",
       "      <th>lineCount</th>\n",
       "      <th>score</th>\n",
       "      <th>actor1match</th>\n",
       "      <th>actor2match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('ChaSeungWon', 'LeeSeungGi')</td>\n",
       "      <td>ChaSeungWon</td>\n",
       "      <td>LeeSeungGi</td>\n",
       "      <td>5</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>SungHyuk, BaeSooBin, SungHyuk, BaeSooBin</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>('JungHaeIn', 'SonYeJin')</td>\n",
       "      <td>JungHaeIn</td>\n",
       "      <td>SonYeJin</td>\n",
       "      <td>9</td>\n",
       "      <td>0.501087</td>\n",
       "      <td>ParkJiBin, ParkJiBin</td>\n",
       "      <td>BangMinAh, KimYooJung, BangMinAh, KimYooJung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>('GoSungHee', 'YoonHyunMin')</td>\n",
       "      <td>GoSungHee</td>\n",
       "      <td>YoonHyunMin</td>\n",
       "      <td>5</td>\n",
       "      <td>0.487549</td>\n",
       "      <td>SeoYeJi</td>\n",
       "      <td>JangKiYong, Chani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>('ChoiJinHyuk', 'SongJiHyo')</td>\n",
       "      <td>ChoiJinHyuk</td>\n",
       "      <td>SongJiHyo</td>\n",
       "      <td>5</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>LeeHyunJin, LeeHyunJin</td>\n",
       "      <td>ShinDongMi, ShinDongMi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>('JungEunJi', 'KimJiSoo')</td>\n",
       "      <td>JungEunJi</td>\n",
       "      <td>KimJiSoo</td>\n",
       "      <td>6</td>\n",
       "      <td>0.466667</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                           pair       actor1  \\\n",
       "0           0             0  ('ChaSeungWon', 'LeeSeungGi')  ChaSeungWon   \n",
       "1           1             1      ('JungHaeIn', 'SonYeJin')    JungHaeIn   \n",
       "2           2             2   ('GoSungHee', 'YoonHyunMin')    GoSungHee   \n",
       "3           3             3   ('ChoiJinHyuk', 'SongJiHyo')  ChoiJinHyuk   \n",
       "4           4             4      ('JungEunJi', 'KimJiSoo')    JungEunJi   \n",
       "\n",
       "        actor2  lineCount     score                               actor1match  \\\n",
       "0   LeeSeungGi          5  0.592857  SungHyuk, BaeSooBin, SungHyuk, BaeSooBin   \n",
       "1     SonYeJin          9  0.501087                      ParkJiBin, ParkJiBin   \n",
       "2  YoonHyunMin          5  0.487549                                   SeoYeJi   \n",
       "3    SongJiHyo          5  0.478333                    LeeHyunJin, LeeHyunJin   \n",
       "4     KimJiSoo          6  0.466667                                             \n",
       "\n",
       "                                    actor2match  \n",
       "0                                                \n",
       "1  BangMinAh, KimYooJung, BangMinAh, KimYooJung  \n",
       "2                             JangKiYong, Chani  \n",
       "3                        ShinDongMi, ShinDongMi  \n",
       "4                                                "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiunclean['actor1match'] = actor1match\n",
    "sentiunclean['actor2match'] = actor2match\n",
    "sentiunclean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will export it into a csv so that we can use it for our dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiunclean.to_csv(\"senti_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
